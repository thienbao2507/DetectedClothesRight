import os
import cv2
import json
import numpy as np
import mediapipe as mp
import tensorflow as tf
from sklearn.metrics.pairwise import cosine_similarity
import torch
from torchvision import transforms
from PIL import Image
from ultralytics import YOLO
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
#12/08
# Load m√¥ h√¨nh helmet
helmet_model = YOLO("best2.pt")
helmet_model.eval()

# ==== ‚öôÔ∏è CONFIG ====
OUTPUT_FOLDER = "check"
RESIZED_SHAPE = (512, 1024)

# Thresholds
THRESH_SKIN_SHOE = 0.4
THRESH_SKIN_ARM = 0.1
THRESH_SKIN_PANTS = 0.02
THRESH_HELMET_CONF = 0.65
THRESH_SMILE_CONF = 0.35
THRESH_NAMETAG_BRIGHT = 170
THRESH_NAMETAG_RATIO = 0.02
THRESH_NAMETAG_AREA = 300

# NORMAL RANGE to find skin
HSV_SKIN_LOOSE = (np.array([0, 30, 60], dtype=np.uint8),  np.array([25, 255, 255], dtype=np.uint8))
YCRCB_SKIN     = (np.array([0, 133, 77], dtype=np.uint8), np.array([255, 173, 127], dtype=np.uint8))

# Range to compare with median skin color
HSV_SKIN_TIGHT = (np.array([4, 40, 60], dtype=np.uint8),  np.array([20, 200, 255], dtype=np.uint8))

# Minimum area ratios to accept a skin hypothesis on the glove crop
MIN_SKIN_AREA_GLOVE_FULL = 0.015
MIN_SKIN_AREA_GLOVE_TIP  = 0.01

def _clean_mask(mask, k=3, iters=1):
    kernel = np.ones((k, k), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=iters)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iters)
    return mask

def make_skin_mask_hsv_ycrcb(bgr_img):
    """T·∫°o mask da b·∫±ng c√°ch giao gi·ªØa HSV v√† YCrCb (loose window), k√®m l·ªçc nhi·ªÖu."""
    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)
    ycc = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YCrCb)

    hsv_mask  = cv2.inRange(hsv,  *HSV_SKIN_LOOSE)
    ycc_mask  = cv2.inRange(ycc,  *YCRCB_SKIN)
    mask      = cv2.bitwise_and(hsv_mask, ycc_mask)
    mask      = _clean_mask(mask, k=3, iters=1)
    return mask, hsv

def median_hsv_on_mask(hsv_img, mask):
    """T√≠nh median (H,S,V) tr√™n c√°c pixel mask>0. Tr·∫£ v·ªÅ None n·∫øu kh√¥ng c√≥ ƒëi·ªÉm."""
    ys, xs = np.where(mask > 0)
    if len(xs) == 0:
        return None
    sel = hsv_img[ys, xs, :]  
    med = np.median(sel, axis=0)  
    return np.array(med, dtype=np.uint8)

def hsv_in_range(hsv_color, rng):
    lo, hi = rng
    return bool(np.all(hsv_color >= lo) and np.all(hsv_color <= hi))

# Load m√¥ h√¨nh ph√°t hi·ªán n·ª• c∆∞·ªùi
smile_model = tf.keras.models.load_model("smilemain.h5")  # ƒë·ªïi t√™n n·∫øu kh√°c
face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1)


# ==== üß† MODEL ====
model = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet',
                                          input_shape=(224, 224, 3), pooling='avg')


def preprocess_person_crop(image_path, ratio_thresh=0.3):
    """
    ƒê·ªçc ·∫£nh v√† ki·ªÉm tra ng∆∞·ªùi trong ·∫£nh c√≥ qu√° nh·ªè kh√¥ng.
    - N·∫øu nh·ªè h∆°n ng∆∞·ª°ng ratio_thresh -> crop s√°t ng∆∞·ªùi, tr·∫£ v·ªÅ ·∫£nh ƒë√£ crop.
    - N·∫øu ok -> tr·∫£ v·ªÅ ·∫£nh g·ªëc.
    """
    print(f"th·ª±c hi·ªán ki·ªÉm tra ·∫£nh")
    image = cv2.imread(image_path)
    if image is None:
        print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
        return None

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=True)
    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    if not results.pose_landmarks:
        print(f"‚ùå Kh√¥ng ph√°t hi·ªán ng∆∞·ªùi trong ·∫£nh: {image_path}")
        return image

    h_raw, w_raw = image.shape[:2]
    landmarks = results.pose_landmarks.landmark
    xs = [int(lm.x * w_raw) for lm in landmarks]
    ys = [int(lm.y * h_raw) for lm in landmarks]

    # üìè T√≠nh bounding box c·ªßa ng∆∞·ªùi
    person_w = max(xs) - min(xs)
    person_h = max(ys) - min(ys)
    person_area = person_w * person_h
    image_area = w_raw * h_raw

    ratio = person_area / image_area
    print(f"üë§ Person ratio: {ratio:.2%}")

    # üëâ N·∫øu ng∆∞·ªùi qu√° nh·ªè th√¨ crop s√°t h∆°n
    if ratio < ratio_thresh:
        margin_x = int(person_w * 0.45)
        margin_y = int(person_h * 0.35)

        x1 = max(min(xs) - margin_x, 0)
        y1 = max(min(ys) - margin_y, 0)
        x2 = min(max(xs) + margin_x, w_raw)
        y2 = min(max(ys) + margin_y, h_raw)

        cropped_img = image[y1:y2, x1:x2]
        print("üìå Person small ‚Üí Cropped tighter image as new base.")
        return cropped_img
    else:
        print("‚úÖ Person ratio ok ‚Üí gi·ªØ nguy√™n ·∫£nh g·ªëc.")
        return image



def extract_embedding(image_path):
    img = cv2.imread(image_path)
    if img is None:
        return None
    img = cv2.resize(img, (224, 224))
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_eq = clahe.apply(l)
    lab_eq = cv2.merge((l_eq, a, b))
    img = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2RGB)

    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)
    img = np.expand_dims(img, axis=0)
    return model.predict(img, verbose=0)


# ==== üì¶ LABELS + COLOR ====
labels = ["nametag", "shirt", "pants", "left_glove", "right_glove",
          "left_shoe", "right_shoe", "left_arm", "right_arm"]
colors = {"pass": (0, 255, 0), "fail": (0, 0, 255), "missing": (128, 128, 128)}


# ===NAMETAG===
def detect_nametag_better(image_input, bright_threshold=THRESH_NAMETAG_BRIGHT,
                           ratio_thresh=THRESH_NAMETAG_RATIO,
                           area_thresh=THRESH_NAMETAG_AREA, show=True):
    if isinstance(image_input, str):
        if not os.path.exists(image_input):
            print("‚ùå File kh√¥ng t·ªìn t·∫°i:", image_input)
            return "missing", None
        img = cv2.imread(image_input)
    elif isinstance(image_input, np.ndarray):
        img = image_input
    else:
        print("‚ùå Input kh√¥ng h·ª£p l·ªá (kh√¥ng ph·∫£i path ho·∫∑c ·∫£nh)")
        return "missing", None
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Threshold ƒë·ªÉ t√¨m v√πng s√°ng (th·∫ª t√™n)
    _, binary = cv2.threshold(gray, bright_threshold, 255, cv2.THRESH_BINARY)

    # T√¨m contours ƒë·ªÉ x√°c ƒë·ªãnh v√πng s√°ng
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    white_ratio = 0.0  # Kh·ªüi t·∫°o white_ratio
    largest_area = 0
    best_box = None
    found = False

    # T√¨m contour l·ªõn nh·∫•t
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > largest_area:
            largest_area = area
            x, y, w, h = cv2.boundingRect(cnt)
            best_box = (x, y, x + w, y + h)
            found = area > area_thresh

    # T√≠nh t·ª∑ l·ªá pixel s√°ng d·ª±a tr√™n contour l·ªõn nh·∫•t
    if largest_area > 0.5:
        white_ratio = largest_area / binary.size
        print(f"üîç Bright pixel ratio (largest cluster): {white_ratio:.2%}")

    if show and found:
        cv2.rectangle(img, (best_box[0], best_box[1]), (best_box[2], best_box[3]), (0, 255, 0), 2)
        cv2.putText(img, f"Area: {int(largest_area)}", (best_box[0], best_box[1] - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return ("pass" if (white_ratio > ratio_thresh or found) else "fail"), best_box


def intersect_with_line(box, p1, p2):
    """
    Ki·ªÉm tra xem bounding box c√≥ c·∫Øt qua ƒë∆∞·ªùng th·∫≥ng p1‚Äìp2 kh√¥ng.
    box: (x1, y1, x2, y2)
    p1, p2: (x, y) ƒëi·ªÉm ƒë·∫ßu ‚Äì cu·ªëi (v√≠ d·ª•: vai -> c·ªï tay)
    """
    x1, y1, x2, y2 = box
    x_min, x_max = min(x1, x2), max(x1, x2)
    y_min, y_max = min(y1, y2), max(y1, y2)

    x_p1, y_p1 = p1
    x_p2, y_p2 = p2

    for alpha in np.linspace(0, 1, 20):  # ki·ªÉm tra 20 ƒëi·ªÉm tr√™n line
        x_line = int((1 - alpha) * x_p1 + alpha * x_p2)
        y_line = int((1 - alpha) * y_p1 + alpha * y_p2)
        if x_min <= x_line <= x_max and y_min <= y_line <= y_max:
            return True
    return False

def evaluate_shirt_color_hsv_direct(img, save_path=None):
    img = cv2.resize(img, (800, int(img.shape[0] * 800 / img.shape[1])))
    h_img, w_img = img.shape[:2]
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # Ng∆∞·ª°ng m√†u
    lower_orange = np.array([0, 70, 70])
    upper_orange = np.array([30, 255, 255])
    blue_range = (np.array([95, 30, 35]), np.array([135, 255, 255]))

    # ROI ph·∫ßn ng·ª±c (s·ªçc cam)
    top = int(h_img * 0.18)
    bottom = int(h_img * 0.42)
    left = int(w_img * 0.05)
    right = int(w_img * 0.95)
    roi = hsv[top:bottom, left:right]

    kernel = np.ones((5, 5), np.uint8)
    roi_mask = cv2.inRange(roi, lower_orange, upper_orange)
    roi_mask = cv2.morphologyEx(roi_mask, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(roi_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    roi_area = roi.shape[0] * roi.shape[1]

    if not contours:
        if save_path:
            debug_img = img.copy()
            cv2.putText(debug_img, "No orange detected", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            cv2.imwrite(save_path, debug_img)
        return "fail"

    largest_cnt = max(contours, key=cv2.contourArea)
    cam_area = cv2.contourArea(largest_cnt)

    # Ki·ªÉm tra ch·∫∑t h∆°n: di·ªán t√≠ch + t·ªâ l·ªá + m·∫≠t ƒë·ªô pixel cam
    x, y, w_box, h_box = cv2.boundingRect(largest_cnt)
    aspect_ratio = w_box / h_box if h_box > 0 else 0
    cam_pixel_ratio = np.sum(roi_mask > 0) / roi_area

    if (cam_area / roi_area < 0.02) or (aspect_ratio < 2.0) or (cam_pixel_ratio < 0.01):
        if save_path:
            debug_img = img.copy()
            cv2.putText(debug_img, "CAM too small/short/insufficient", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            cv2.imwrite(save_path, debug_img)
        return "fail"

    # X√°c ƒë·ªãnh l·∫°i v√πng cam tuy·ªát ƒë·ªëi
    x_abs = x + left
    y_abs = y + top
    cam_roi = hsv[y_abs:y_abs + h_box, x_abs:x_abs + w_box]
    cam_mask = cv2.inRange(cam_roi, lower_orange, upper_orange)
    cam_mean = np.array(cv2.mean(cam_roi, mask=cam_mask)[:3])

    # Ki·ªÉm tra v√πng xanh b√™n d∆∞·ªõi
    bot_hsv = hsv[y_abs + h_box:, x_abs:x_abs + w_box]
    bot_mean = np.array(cv2.mean(bot_hsv)[:3])

    def in_range(color, color_range):
        lower, upper = color_range
        return np.all(color >= lower) and np.all(color <= upper)

    cam_match = np.sum(cam_mask > 0) > 0
    bottom_match = in_range(bot_mean, blue_range)

    result = "pass" if cam_match and bottom_match else "fail"

    # V·∫Ω debug n·∫øu c·∫ßn
    if save_path:
        debug_img = img.copy()

        # CAM
        cv2.rectangle(debug_img, (x_abs, y_abs), (x_abs + w_box, y_abs + h_box), (0, 165, 255), 2)
        cv2.putText(debug_img, "CAM", (x_abs, y_abs - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                    (0, 165, 255), 1)

        # BLUE
        cv2.rectangle(debug_img, (x_abs, y_abs + h_box), (x_abs + w_box, h_img), (255, 0, 0), 2)
        cv2.putText(debug_img, "BLUE", (x_abs, y_abs + h_box + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                    (255, 0, 0), 1)

        if result == "fail":
            if not cam_match:
                cv2.putText(debug_img, "‚ùå Sai CAM", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            if not bottom_match:
                cv2.putText(debug_img, "‚ùå Sai BLUE (Duoi)", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        else:
            cv2.putText(debug_img, "‚úÖ Dung mau dong phuc", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 200, 0), 2)

        cv2.imwrite(save_path, debug_img)

    return result


# ==== üìå POSE CROP ====
def crop_pose(image_path, save_folder):
    # Lu√¥n g·ªçi preprocess_person_crop tr∆∞·ªõc
    if isinstance(image_path, np.ndarray):
        # L∆∞u ·∫£nh t·∫°m ƒë·ªÉ h√†m preprocess_person_crop x·ª≠ l√Ω
        temp_path = "temp_input.jpg"
        cv2.imwrite(temp_path, image_path)
        image = preprocess_person_crop(temp_path, ratio_thresh=0.3)
    else:
        image = preprocess_person_crop(image_path, ratio_thresh=0.3)

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=True)
    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    if not results.pose_landmarks:
        print(f"‚ùå Kh√¥ng ph√°t hi·ªán ng∆∞·ªùi trong ·∫£nh: {image_path}")
        return {}, {}, image

    landmarks = results.pose_landmarks.landmark
    h_raw, w_raw = image.shape[:2]
    points = [(int(lm.x * w_raw), int(lm.y * h_raw)) for lm in landmarks]

    xs = [p[0] for p in points]
    ys = [p[1] for p in points]

    margin_x = 350
    margin_y = 500

    x1 = max(min(xs) - margin_x, 0)
    y1 = max(min(ys) - margin_y, 0)
    x2 = min(max(xs) + margin_x, w_raw)
    y2 = min(max(ys) + margin_y, h_raw)

    # C·∫Øt v√πng ch·ª©a ng∆∞·ªùi
    image = image[y1:y2, x1:x2]
    image = cv2.resize(image, RESIZED_SHAPE)
    h, w, _ = image.shape
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=True)
    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    if not results.pose_landmarks:
        print(f"‚ùå Kh√¥ng ph√°t hi·ªán ng∆∞·ªùi trong ·∫£nh: {image_path}")
        return {}, {}, image

    landmarks = results.pose_landmarks.landmark

    def get_point(lm):
        return int(lm.x * w), int(lm.y * h)

    crops = {}
    crop_images = {}

    def save_crop(label, x1, y1, x2, y2):
        if 0 <= x1 < x2 <= w and 0 <= y1 < y2 <= h:
            crop = image[y1:y2, x1:x2]
            crops[label] = {"x1": x1, "y1": y1, "x2": x2, "y2": y2}
            crop_images[label] = crop

    # ƒêi·ªÉm landmark ch√≠nh
    ls, rs = landmarks[11], landmarks[12]
    lw, rw = landmarks[15], landmarks[16]
    la, ra = landmarks[27], landmarks[28]
    lh, rh = landmarks[23], landmarks[24]

    # Nametag
    x1, y1 = get_point(ls)
    x2, y2 = get_point(rs)
    cx1 = int((x1 + x2) * 0.5)
    cx2 = max(x1, x2) + 10
    cy1 = int((y1 + y2) * 0.5 + 0.08 * h) - 20
    cy2 = cy1 + 100  # ƒë·ªô d√†i
    save_crop("nametag", cx1, cy1, cx2, cy2)

    # GƒÉng tay
    def crop_hand(label, ids):
        pts = [landmarks[i] for i in ids]
        xs = [int(p.x * w) for p in pts]
        ys = [int(p.y * h) for p in pts]
        margin_x, margin_y = 30, 50
        save_crop(label, min(xs) - margin_x, min(ys) - margin_y, max(xs) + margin_x, max(ys) + margin_y)

    crop_hand("left_glove", [15, 17, 19, 21])
    crop_hand("right_glove", [16, 18, 20, 22])

    # Gi√†y
    for label, pt in zip(["left_shoe", "right_shoe"], [la, ra]):
        px, py = get_point(pt)
        save_crop(label, px - 50, py - 20, px + 50, py + 60)

    # √Åo
    x_ls, y_ls = get_point(ls)
    x_rs, y_rs = get_point(rs)
    shirt_x1 = min(x_ls, x_rs) - 20
    shirt_y1 = min(y_ls, y_rs) - 40
    shirt_x2 = max(x_ls, x_rs) + 20
    shirt_y2 = int((lh.y + rh.y) / 2 * h)
    save_crop("shirt", shirt_x1, shirt_y1, shirt_x2, shirt_y2)

    # Qu·∫ßn
    lx, ly = get_point(lh)
    rx, ry = get_point(rh)
    ankle_y = max(get_point(la)[1], get_point(ra)[1])
    save_crop("pants", min(lx, rx) - 80, min(ly, ry), max(lx, rx) + 80, ankle_y - 10)

    # C√°nh tay
    for label, shoulder, wrist in zip(["left_arm", "right_arm"], [ls, rs], [lw, rw]):
        sx, sy = get_point(shoulder)
        wx, wy = get_point(wrist)
        save_crop(label, min(sx, wx) - 30, min(sy, wy) - 30, max(sx, wx) + 30, max(sy, wy) + 30)

    # === CROP V√ôNG ƒê·∫¶U (HELMET) ===
    head_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8]  # m≈©i, m·∫Øt, mi·ªáng, tai
    head_points = [get_point(landmarks[i]) for i in head_ids]
    xs = [p[0] for p in head_points]
    ys = [p[1] for p in head_points]

    # M·ªü r·ªông v√πng ƒë·∫ßu ƒë·ªÉ l·∫•y c·∫£ n√≥n
    margin_x, margin_y = 60, 70
    extra_top_margin = 30  # ‚úÖ m·ªü r·ªông th√™m l√™n ph√≠a tr√™n

    x1 = max(min(xs) - margin_x, 0)
    y1 = max(min(ys) - margin_y - extra_top_margin, 0)
    x2 = min(max(xs) + margin_x, w)
    y2 = min(max(ys) + margin_y, h)

    save_crop("helmet", x1, y1, x2, y2)

    # === CROP V√ôNG M·∫∂T (M·ªû R·ªòNG TO√ÄN B·ªò) ===
    x_min = min(xs)
    x_max = max(xs)
    y_min = min(ys)
    y_max = max(ys)

    face_width = x_max - x_min
    face_height = y_max - y_min

    margin_x = int(face_width * 0.15)   # m·ªü r·ªông 5% chi·ªÅu ngang
    margin_y = int(face_height * 2.7)  # m·ªü r·ªông 30% chi·ªÅu d·ªçc

    fx1 = max(x_min - margin_x, 0)
    fx2 = min(x_max + margin_x, w)
    fy1 = max(y_min - margin_y, 0)
    fy2 = min(y_max + margin_y, h)

    save_crop("face_smile", fx1, fy1, fx2, fy2)
# === L∆∞u ·∫£nh face_smile ra th∆∞ m·ª•c ƒë·ªÉ ki·ªÉm tra sau ===
    face_crop_folder = os.path.join("check", "face_crop")
    os.makedirs(face_crop_folder, exist_ok=True)

    # T·∫°o t√™n file: n·∫øu image_path l√† str th√¨ l·∫•y t√™n file, n·∫øu l√† ·∫£nh numpy th√¨ d√πng m·∫∑c ƒë·ªãnh
    import uuid
    if isinstance(image_path, str):
        base_name = os.path.splitext(os.path.basename(image_path))[0]
    else:
        base_name = str(uuid.uuid4())  # t·∫°o t√™n ng·∫´u nhi√™n n·∫øu kh√¥ng c√≥ t√™n ·∫£nh

    face_crop_path = os.path.join(face_crop_folder, f"{base_name}_face.jpg")
    cv2.imwrite(face_crop_path, crop_images["face_smile"])

    return crops, crop_images, image, landmarks


def extract_shirt_colors(image_path):
    img = cv2.imread(image_path)
    if img is None:
        return None
    img = cv2.resize(img, (300, 300))  # ƒë·∫£m b·∫£o t·ª∑ l·ªá chu·∫©n

    h = img.shape[0]
    top = img[0:int(h / 3), :, :]
    mid = img[int(h / 3):int(2 * h / 3), :, :]
    bot = img[int(2 * h / 3):, :, :]

    color_top = np.mean(top.reshape(-1, 3), axis=0)
    color_mid = np.mean(mid.reshape(-1, 3), axis=0)
    color_bot = np.mean(bot.reshape(-1, 3), axis=0)

    return {
        "top": color_top,
        "mid": color_mid,
        "bot": color_bot
    }


def detect_smile(face_img, threshold=THRESH_SMILE_CONF):
    """
    Ph√°t hi·ªán n·ª• c∆∞·ªùi t·ª´ ·∫£nh m·∫∑t ƒë√£ crop (grayscale 32x32).
    Tr·∫£ v·ªÅ 'smile' ho·∫∑c 'no_smile' t√πy theo ng∆∞·ª°ng confidence.
    """
    if face_img is None:
        return "missing"

    # Chuy·ªÉn v·ªÅ grayscale v√† resize
    gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, (32, 32), interpolation=cv2.INTER_AREA)

    # Chu·∫©n h√≥a v√† reshape
    array_img = img_to_array(resized)
    array_img = array_img.astype("float") / 255.0
    array_img = np.expand_dims(array_img, axis=0)  # (1, 32, 32, 1)

    # D·ª± ƒëo√°n
    prediction = smile_model.predict(array_img, verbose=0)
    confidence = float(prediction[0][0])  # ƒë·∫ßu ra sigmoid

    label_map = {0: "no_smile", 1: "smile"}
    predicted_label = int(round(confidence))
    predicted_class = label_map[predicted_label]

    print(f"üôÇ Smile confidence: {confidence:.2%} ‚Üí {predicted_class}")

    # D√πng ng∆∞·ª°ng ƒë·ªÉ tr·∫£ k·∫øt qu·∫£ m·ªÅm h∆°n (n·∫øu mu·ªën)
    return "smile" if confidence > threshold else "no_smile"


def intersect_with_leg_line(box, knee, ankle):
    """
    Ki·ªÉm tra xem bounding box c√≥ c·∫Øt qua ƒë∆∞·ªùng th·∫≥ng t·ª´ ƒë·∫ßu g·ªëi ƒë·∫øn g√≥t ch√¢n kh√¥ng.

    Args:
        box: tuple (x1, y1, x2, y2) ‚Äì to·∫° ƒë·ªô v√πng da
        knee: tuple (x, y) ‚Äì to·∫° ƒë·ªô ƒë·∫ßu g·ªëi
        ankle: tuple (x, y) ‚Äì to·∫° ƒë·ªô g√≥t ch√¢n

    Returns:
        True n·∫øu c·∫Øt qua, False n·∫øu n·∫±m l·ªách ngo√†i
    """
    x1, y1, x2, y2 = box
    x_min, x_max = min(x1, x2), max(x1, x2)
    y_min, y_max = min(y1, y2), max(y1, y2)

    # T·ªça ƒë·ªô ƒëi·ªÉm ƒë·∫ßu v√† cu·ªëi ƒë∆∞·ªùng tr·ª•c ch√¢n
    x_knee, y_knee = knee
    x_ankle, y_ankle = ankle

    # Duy·ªát theo chi·ªÅu y, ki·ªÉm tra t·ª´ng ƒëi·ªÉm tr√™n ƒë∆∞·ªùng tr·ª•c
    for alpha in np.linspace(0, 1, 20):  # ki·ªÉm tra 20 ƒëi·ªÉm tr√™n ƒëo·∫°n th·∫≥ng
        x_line = int((1 - alpha) * x_knee + alpha * x_ankle)
        y_line = int((1 - alpha) * y_knee + alpha * y_ankle)

        if x_min <= x_line <= x_max and y_min <= y_line <= y_max:
            return True  # C√≥ giao

    return False  # Kh√¥ng c·∫Øt qua


# ==DeLoy==
def run_inference(test_image_path):
    # T·∫°o l·∫°i th∆∞ m·ª•c k·∫øt qu·∫£
    os.makedirs(f"{OUTPUT_FOLDER}/anchor", exist_ok=True)
    os.makedirs(f"{OUTPUT_FOLDER}/test", exist_ok=True)
    box_errors = []

    # ==== üìå POSE CROP ====
    print("üîß ƒêang crop ·∫£nh test...")
    test_boxes, test_crops, test_image, test_landmarks = crop_pose(test_image_path, f"{OUTPUT_FOLDER}/test")

    results = {}
    early_fail = False
    all_labels = labels.copy()

    for label in all_labels:

        if label in ["left_arm", "right_arm"]:
            continue
        if label in ["left_glove", "right_glove"]:
            img = test_crops.get(label)
            if img is None:
                results[label] = "missing"
                continue

            # === NEW: t·∫°o mask da b·∫±ng HSV‚à©YCrCb, t√≠nh median HSV v√† x√°c nh·∫≠n b·∫±ng HSV_SKIN_TIGHT ===
            mask_full, hsv_full = make_skin_mask_hsv_ycrcb(img)
            skin_ratio_full = float(np.sum(mask_full > 0)) / mask_full.size

            median_full = median_hsv_on_mask(hsv_full, mask_full)
            median_is_skin = (median_full is not None) and hsv_in_range(median_full, HSV_SKIN_TIGHT)

            # ROI ƒë·∫ßu ng√≥n tay (1/3 d∆∞·ªõi)
            h_img = img.shape[0]
            roi_tip = img[int(h_img * 2 / 3):, :]
            mask_tip, hsv_tip = make_skin_mask_hsv_ycrcb(roi_tip)
            skin_ratio_tip = float(np.sum(mask_tip > 0)) / mask_tip.size
            median_tip = median_hsv_on_mask(hsv_tip, mask_tip)
            median_tip_is_skin = (median_tip is not None) and hsv_in_range(median_tip, HSV_SKIN_TIGHT)
            print(f"[{label}] full area={skin_ratio_full:.2%}, median={median_full}, in_tight={median_is_skin}")
            print(f"[{label}]  tip area={skin_ratio_tip:.2%}, median={median_tip},  in_tight={median_tip_is_skin}")
            # Quy t·∫Øc quy·∫øt ƒë·ªãnh:
            # - Fail n·∫øu (di·ªán t√≠ch ƒë·ªß l·ªõn) V√Ä (m√†u trung v·ªã r∆°i v√†o skin HSV ch·∫∑t).
            full_fail = (skin_ratio_full >= MIN_SKIN_AREA_GLOVE_FULL) and median_is_skin
            tip_fail  = (skin_ratio_tip  >= MIN_SKIN_AREA_GLOVE_TIP)  and median_tip_is_skin

            result = "fail" if (full_fail or tip_fail) else "pass"
            results[label] = result

            # V·∫Ω box l·ªói (n·∫øu fail) l√™n ·∫£nh t·ªïng: d√πng v√πng mask l·ªõn nh·∫•t (full) ƒë·ªÉ t·∫°o bbox
            if result == "fail" and label in test_boxes:
                contours, _ = cv2.findContours(mask_full, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                big = None
                if contours:
                    big = max(contours, key=cv2.contourArea)
                if big is not None and cv2.contourArea(big) >= 50:
                    x, y, w_box, h_box = cv2.boundingRect(big)
                    box = test_boxes[label]
                    x1 = box["x1"] + x
                    y1 = box["y1"] + y
                    x2 = x1 + w_box
                    y2 = y1 + h_box
                    box_errors.append({
                        "label": f"{label}_skin",
                        "box": (x1, y1, x2, y2),
                        "color": (0, 0, 255)
                    })
            # ti·∫øp t·ª•c v√≤ng l·∫∑p labels



        if label == "nametag":
            if early_fail:
                results[label] = "fail"
                continue
            img = test_crops.get(label)
            if img is not None:
                result, nametag_box = detect_nametag_better(img)
            else:
                result = "missing"
                nametag_box = None
            offset = test_boxes["nametag"]
            if nametag_box:
                x1_crop, y1_crop, x2_crop, y2_crop = nametag_box
                x1 = offset["x1"] + x1_crop
                y1 = offset["y1"] + y1_crop
                x2 = offset["x1"] + x2_crop
                y2 = offset["y1"] + y2_crop
            results[label] = result

        else:
            if label == "shirt":
                shirt_img = test_crops.get("shirt")
                result = "missing"
                if shirt_img is not None:
                    result = evaluate_shirt_color_hsv_direct(shirt_img)
                    results["shirt"] = result
            if label in ["shirt", "pants"] and result == "fail":
                early_fail = True
                # N·∫øu pants l√† pass, ki·ªÉm tra xem c√≥ b·ªã s·∫Øn (l·ªô da) kh√¥ng
            if label == "pants":
                img = test_crops.get("pants")
                if img is not None:
                    result = "pass"
                    h = img.shape[0]
                    start_row = int(h * 1 / 2)
                    lower_part = img[start_row:, :]

                    hsv = cv2.cvtColor(lower_part, cv2.COLOR_BGR2HSV)
                    lower = np.array([0, 20, 70], dtype=np.uint8)
                    upper = np.array([20, 255, 255], dtype=np.uint8)
                    mask = cv2.inRange(hsv, lower, upper)
                    skin_ratio = np.sum(mask == 255) / mask.size
                    print(f"[PANTS S·∫ÆN] Skin ratio (lower): {skin_ratio:.2%}")

                    if skin_ratio > THRESH_SKIN_PANTS:
                        # ======= B·ªî SUNG: In ra v·ªã tr√≠ v√πng da so v·ªõi ƒë·∫ßu g·ªëi v√† g√≥t ch√¢n ========
                        def get_point(lm):  # Convert landmark to pixel
                            return int(lm.x * test_image.shape[1]), int(lm.y * test_image.shape[0])

                        left_knee = get_point(test_landmarks[25])
                        right_knee = get_point(test_landmarks[26])
                        left_ankle = get_point(test_landmarks[27])
                        right_ankle = get_point(test_landmarks[28])

                        print(f"LEFT_KNEE: {left_knee}")
                        print(f"RIGHT_KNEE: {right_knee}")
                        print(f"LEFT_ANKLE: {left_ankle}")
                        print(f"RIGHT_ANKLE: {right_ankle}")

                        if label in test_boxes:
                            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                            for cnt in contours:
                                if cv2.contourArea(cnt) < 50:
                                    continue
                                x, y, w, h_cnt = cv2.boundingRect(cnt)
                                box = test_boxes["pants"]
                                x1 = box["x1"] + x
                                y1 = box["y1"] + start_row + y
                                x2 = x1 + w
                                y2 = y1 + h_cnt
                                region_box = (x1, y1, x2, y2)

                                # üß† Ki·ªÉm tra c√≥ giao v·ªõi tr·ª•c ch√¢n kh√¥ng
                                if intersect_with_leg_line(region_box, left_knee, left_ankle) or \
                                        intersect_with_leg_line(region_box, right_knee, right_ankle):
                                    print("‚úÖ V√πng da giao v·ªõi ch√¢n ‚Üí l√† l·ªói th·∫≠t")
                                    test_boxes["pants_rolled_up"] = {"x1": x1, "y1": y1, "x2": x2, "y2": y2}
                                    all_labels.append("pants_rolled_up")
                                    results["pants_rolled_up"] = "fail"
                                    box_errors.append({
                                        "label": "pants_rolled_up",
                                        "box": (x1, y1, x2, y2),
                                        "color": (0, 0, 255)
                                    })
                                else:
                                    print("‚ùå B·ªè qua v√πng da kh√¥ng n·∫±m tr√™n ch√¢n")

                results["pants"] = result
        if label in ["left_shoe", "right_shoe"]:
            img = test_crops.get(label)
            if img is None:
                result = "missing"
            else:
                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
                lower = np.array([0, 40, 90])
                upper = np.array([18, 150, 255])
                mask = cv2.inRange(hsv, lower, upper)
                skin_ratio = np.sum(mask == 255) / mask.size
                print(f"[{label.upper()}] Skin ratio (shoe): {skin_ratio:.2%}")
                result = "fail" if skin_ratio > THRESH_SKIN_SHOE  else "pass"
            results[label] = result
        if label == "shirt" and result == "pass":
            for arm_label in ["left_arm", "right_arm"]:
                img = test_crops.get(arm_label)
                if img is None:
                    results[arm_label] = "missing"
                    continue

                # C·∫Øt 2/3 d∆∞·ªõi ·∫£nh tay ƒë·ªÉ tr√°nh v√πng vai
                h = img.shape[0]
                roi = img[int(h / 3):, :]  # t·ª´ 1/3 chi·ªÅu cao tr·ªü xu·ªëng

                # X·ª≠ l√Ω HSV tr√™n ROI
                hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
                lower = np.array([0, 20, 70], dtype=np.uint8)
                upper = np.array([20, 255, 255], dtype=np.uint8)
                mask = cv2.inRange(hsv, lower, upper)
                skin_ratio = np.sum(mask == 255) / mask.size

                print(f"[{arm_label.upper()}] skin ratio: {skin_ratio:.2%}")

                if skin_ratio > THRESH_SKIN_ARM:
                    if arm_label in test_boxes:
                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        for cnt in contours:
                            if cv2.contourArea(cnt) < 100:
                                continue
                            x, y, w, h_box = cv2.boundingRect(cnt)
                            box = test_boxes[arm_label]
                            x1 = box["x1"] + x
                            y1 = box["y1"] + int(h / 3) + y
                            x2 = x1 + w
                            y2 = y1 + h_box
                            region_box = (x1, y1, x2, y2)

                            # ‚úÖ L·∫•y landmark vai & c·ªï tay
                            if arm_label == "left_arm":
                                shoulder = test_landmarks[11]  # left_shoulder
                                wrist = test_landmarks[15]  # left_wrist
                            else:
                                shoulder = test_landmarks[12]  # right_shoulder
                                wrist = test_landmarks[16]  # right_wrist

                            def get_point(lm):
                                return int(lm.x * test_image.shape[1]), int(lm.y * test_image.shape[0])

                            shoulder_pt = get_point(shoulder)
                            wrist_pt = get_point(wrist)

                            # ‚úÖ Ki·ªÉm tra v√πng da c√≥ giao v·ªõi line vai‚Äìc·ªï tay kh√¥ng
                            if intersect_with_line(region_box, shoulder_pt, wrist_pt):
                                results[arm_label] = "fail"
                                box_errors.append({
                                    "label": f"{arm_label}_skin",
                                    "box": region_box,
                                    "color": (0, 0, 255)
                                })
                            else:
                                print(f"‚ùå {arm_label} v√πng da kh√¥ng giao v·ªõi c√°nh tay ‚Üí b·ªè qua")
                else:
                    results[arm_label] = "pass"

        # results[label] = result
        DRAW_FAIL_LABELS = [
            "nametag", "left_glove", "right_glove",
            "pants", "pants_rolled_up", "left_arm_skin", "right_arm_skin",
            "left_shoe", "right_shoe", "shirt", "helmet"
        ]
        # üé® V·∫Ω khung l√™n ·∫£nh
        if result == "fail" and label in DRAW_FAIL_LABELS and label in test_boxes:
            color = colors["fail"]
            box = test_boxes[label]
            cv2.rectangle(test_image, (box["x1"], box["y1"]), (box["x2"], box["y2"]), color, 2)
            cv2.putText(test_image, f"{label}: {result}", (box["x1"], box["y1"] - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # === V·∫Ω th√™m t·∫•t c·∫£ c√°c l·ªói ph·ª• t·ª´ box_errors ===
        for error in box_errors:
            err_label = error["label"]
            if err_label not in DRAW_FAIL_LABELS:
                continue  # b·ªè qua c√°c l·ªói kh√¥ng c·∫ßn v·∫Ω
            x1, y1, x2, y2 = error["box"]
            color = error.get("color", (0, 0, 255))
            cv2.rectangle(test_image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(test_image, err_label, (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    # ==== HELMET CHECK ====
    helmet_path = test_image_path
    if helmet_path is not None:
        results_helmet = helmet_model(helmet_path)[0]  # YOLO tr·∫£ v·ªÅ list, l·∫•y ph·∫ßn ƒë·∫ßu
        names = results_helmet.names  # danh s√°ch class names
        detected = False

        for box in results_helmet.boxes:
            cls_id = int(box.cls[0].item())
            cls_name = names[cls_id].lower()
            print("Helmet Detection:", cls_name)
            conf = float(box.conf[0])  # l·∫•y ƒë·ªô t·ª± tin
            print(f"ü™ñ Helmet Detection: {cls_name}, Confidence: {conf:.2%}")
            if "helmet" in cls_name and conf >= THRESH_HELMET_CONF:
                detected = True
                break

        if detected:
            results["helmet"] = "pass"
        else:
            results["helmet"] = "fail"
            box = test_boxes.get("helmet")
            if box:
                x1, y1, x2, y2 = box["x1"], box["y1"], box["x2"], box["y2"]
                cv2.rectangle(test_image, (x1, y1), (x2, y2), colors["fail"], 2)
                cv2.putText(test_image, "helmet: fail", (x1, y1 - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors["fail"], 2)
    else:
        results["helmet"] = "missing"
    face_crop = test_crops.get("face_smile")
    if face_crop is not None:
        smile_result = detect_smile(face_crop)
    else:
        smile_result = "missing"

    results["smile"] = smile_result
    # ==== üíæ OUTPUT ====

    output_path = os.path.join(OUTPUT_FOLDER, "test_result.jpg")
    cv2.imwrite(output_path, test_image)

    return output_path, results